{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T09:02:53.997527Z",
     "start_time": "2018-09-24T09:02:53.178387Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kentaro.nakanishi/.pyenv/versions/3.6.5/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/kentaro.nakanishi/.pyenv/versions/3.6.5/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from utils.config import Config\n",
    "from dataloader.docomo_datasource import DocomoDataSource\n",
    "from models.transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T09:02:54.000300Z",
     "start_time": "2018-09-24T09:02:53.998632Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T09:02:54.070104Z",
     "start_time": "2018-09-24T09:02:54.001327Z"
    }
   },
   "outputs": [],
   "source": [
    "#config = Config()\n",
    "#ds = DocomoDataSource(config)\n",
    "#ds.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T09:02:54.164903Z",
     "start_time": "2018-09-24T09:02:54.071158Z"
    }
   },
   "outputs": [],
   "source": [
    "units = [256, 512]\n",
    "layers = [2, 4, 6]\n",
    "lrs = [0.001]\n",
    "configs = []\n",
    "for l in layers:\n",
    "    for u in units:\n",
    "        for lr in lrs:\n",
    "            configs.append(Config(num_layers=l, num_units=u, learning_rate=lr, log_dir='./logs/transformer/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T09:02:54.274418Z",
     "start_time": "2018-09-24T09:02:54.166027Z"
    }
   },
   "outputs": [],
   "source": [
    "config = Config(num_layers=4, num_units=512, learning_rate=0.001, log_dir='./logs/ut/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T09:02:54.364479Z",
     "start_time": "2018-09-24T09:02:54.275812Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "import tensorflow as tf\n",
    "from utils import transformer\n",
    "from utils import utils\n",
    "\n",
    "\n",
    "class UnivTransformer:\n",
    "\n",
    "    def __init__(self, config, scope='universal_transformer', reuse: bool=None) -> None:\n",
    "\n",
    "        # instance var\n",
    "        self.config = config\n",
    "        self.scope = scope\n",
    "\n",
    "        self.build_model(scope, reuse)\n",
    "        self.init_global_step()\n",
    "        self.init_saver()\n",
    "\n",
    "    def init_saver(self):\n",
    "        self.saver = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.scope))\n",
    "\n",
    "    def init_global_step(self):\n",
    "        self.global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    def save(self, sess):\n",
    "        self.saver.save(sess, self.config.checkpoint_path, self.global_step)\n",
    "\n",
    "    def load(self, sess: tf.Session, path: str) -> None:\n",
    "        '''\n",
    "        モデルを読み込みます。\n",
    "        :param sess: セッション\n",
    "        :param path: モデルのパス。以下のいずれか\n",
    "            - S3 上のファイルパス(s3://.../model.ckpt)\n",
    "            - ローカルのディレクトリパス：ディレクトリをチェックポイントディレクトリとみなし\n",
    "              最新のチェックポイントを読み込みます\n",
    "            - ローカルのファイルパス： .../model.ckpt\n",
    "        '''\n",
    "        model_path = utils.get_model_path(path)\n",
    "        if model_path:\n",
    "            print(\"Loading model {} ...\\n\".format(model_path))\n",
    "            self.saver.restore(sess, model_path)\n",
    "            print(\"Model loaded\")\n",
    "\n",
    "    def build_model(self, scope, reuse: Optional[bool]):\n",
    "        with tf.variable_scope(scope, reuse=reuse):\n",
    "            # placeholder\n",
    "            self.is_training = tf.placeholder(dtype=tf.bool, name='is_training')\n",
    "            self.encoder_inputs = tf.placeholder(\n",
    "                dtype=tf.int32,\n",
    "                shape=[None, self.config.max_length],\n",
    "                name='encoder_inputs'\n",
    "            )\n",
    "            self.decoder_targets = tf.placeholder(\n",
    "                dtype=tf.int32,\n",
    "                shape=[None, self.config.max_length],\n",
    "                name='decoder_targets'\n",
    "            )\n",
    "            self.decoder_inputs = tf.placeholder(\n",
    "                dtype=tf.int32,\n",
    "                shape=[None, self.config.max_length],\n",
    "                name='decoder_inputs'\n",
    "            )\n",
    "\n",
    "            # building\n",
    "            sent_encoder_inputs_embedded = self._encoder()\n",
    "            self.decoder_logits = self._decoder(sent_encoder_inputs_embedded, self.decoder_inputs)\n",
    "\n",
    "        is_target = tf.to_float(tf.not_equal(self.decoder_targets, 0))\n",
    "        # loss\n",
    "        decoder_targets_one_hot = tf.one_hot(self.decoder_targets, self.config.vocab_size)\n",
    "        decoder_targets_smoothed = utils.label_smoothing(decoder_targets_one_hot)\n",
    "        cross_ents = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            logits=self.decoder_logits,\n",
    "            labels=decoder_targets_smoothed\n",
    "        )\n",
    "        #self.loss = tf.reduce_sum(cross_ents * is_target) / tf.reduce_sum(is_target)\n",
    "        self.loss = tf.reduce_mean(cross_ents)\n",
    "\n",
    "        # acc\n",
    "        predicted_ids = tf.to_int32(tf.argmax(self.decoder_logits, axis=2))\n",
    "        correct = tf.equal(predicted_ids, self.decoder_targets)\n",
    "        #self.accuracy = tf.reduce_sum(tf.to_float(correct)*is_target) / (tf.reduce_sum(is_target))\n",
    "        self.accuracy = tf.reduce_mean(tf.to_float(correct))\n",
    "\n",
    "    def _encoder(self):\n",
    "        with tf.variable_scope('encoder'):\n",
    "            encoder_inputs_embedded = transformer.embedding(\n",
    "                self.encoder_inputs,\n",
    "                self.config.vocab_size,\n",
    "                self.config.num_units,\n",
    "                is_scale=True,\n",
    "                scope='enc_embed'\n",
    "            )\n",
    "            encoder_inputs_embedded += transformer.positional_encoding(\n",
    "                self.encoder_inputs,\n",
    "                num_units=self.config.num_units,\n",
    "                is_zero_pad=True,\n",
    "            )\n",
    "            encoder_inputs_embedded = tf.layers.dropout(\n",
    "                encoder_inputs_embedded,\n",
    "                rate=self.config.dropout_in_rate,\n",
    "                training=self.is_training\n",
    "            )\n",
    "\n",
    "            for i in range(self.config.num_pre_layers):\n",
    "                with tf.variable_scope('pre_blocks_{}'.format(i)):\n",
    "                    encoder_inputs_embedded = transformer.multihead_attention(\n",
    "                        queries=encoder_inputs_embedded,\n",
    "                        keys=encoder_inputs_embedded,\n",
    "                        is_training=self.is_training,\n",
    "                        dropout_rate=self.config.dropout_in_rate,\n",
    "                        num_units=self.config.num_units,\n",
    "                        num_heads=self.config.num_heads,\n",
    "                        is_causality=False\n",
    "                    )\n",
    "\n",
    "                    encoder_inputs_embedded = transformer.feedforward(\n",
    "                        encoder_inputs_embedded,\n",
    "                        num_units=[4*self.config.num_units, self.config.num_units],\n",
    "                        scope='hier_feedforward'\n",
    "                    )\n",
    "            for i in range(self.config.num_layers):\n",
    "                with tf.variable_scope('share_blocks'):\n",
    "                    encoder_inputs_embedded += transformer.positional_encoding2(\n",
    "                        encoder_inputs_embedded,\n",
    "                        is_zero_pad=True\n",
    "                    )\n",
    "                    encoder_inputs_embedded += transformer.step_encoding(\n",
    "                        encoder_inputs_embedded,\n",
    "                        i,\n",
    "                        is_zero_pad=True\n",
    "                    )\n",
    "                    encoder_inputs_embedded = transformer.multihead_attention(\n",
    "                        queries=encoder_inputs_embedded,\n",
    "                        keys=encoder_inputs_embedded,\n",
    "                        is_training=self.is_training,\n",
    "                        dropout_rate=self.config.dropout_in_rate,\n",
    "                        num_units=self.config.num_units,\n",
    "                        num_heads=self.config.num_heads,\n",
    "                        is_causality=False\n",
    "                    )\n",
    "\n",
    "                    encoder_inputs_embedded = transformer.feedforward(\n",
    "                        encoder_inputs_embedded,\n",
    "                        num_units=[4*self.config.num_units, self.config.num_units],\n",
    "                        scope='hier_feedforward'\n",
    "                    )\n",
    "            for i in range(self.config.num_post_layers):\n",
    "                with tf.variable_scope('post_blocks_{}'.format(i)):\n",
    "                    encoder_inputs_embedded = transformer.multihead_attention(\n",
    "                        queries=encoder_inputs_embedded,\n",
    "                        keys=encoder_inputs_embedded,\n",
    "                        is_training=self.is_training,\n",
    "                        dropout_rate=self.config.dropout_in_rate,\n",
    "                        num_units=self.config.num_units,\n",
    "                        num_heads=self.config.num_heads,\n",
    "                        is_causality=False\n",
    "                    )\n",
    "\n",
    "                    encoder_inputs_embedded = transformer.feedforward(\n",
    "                        encoder_inputs_embedded,\n",
    "                        num_units=[4*self.config.num_units, self.config.num_units],\n",
    "                        scope='hier_feedforward'\n",
    "                    )\n",
    "\n",
    "            return encoder_inputs_embedded\n",
    "\n",
    "    def _decoder(self, hier_encoder_inputs_embedded, decoder_inputs):\n",
    "        with tf.variable_scope('decoder'):\n",
    "            decoder_inputs_embedded = transformer.embedding(\n",
    "                decoder_inputs,\n",
    "                vocab_size=self.config.vocab_size,\n",
    "                num_units=self.config.num_units,\n",
    "                is_scale=True,\n",
    "                scope='dec_embed'\n",
    "            )\n",
    "            decoder_inputs_embedded += transformer.positional_encoding(\n",
    "                decoder_inputs,\n",
    "                num_units=self.config.num_units,\n",
    "                is_zero_pad=True,\n",
    "            )\n",
    "\n",
    "            for i in range(self.config.num_pre_layers):\n",
    "                with tf.variable_scope('pre_blocks_{}'.format(i)):\n",
    "                    decoder_inputs_embedded = transformer.multihead_attention(\n",
    "                        queries=decoder_inputs_embedded,\n",
    "                        keys=decoder_inputs_embedded,\n",
    "                        is_training=self.is_training,\n",
    "                        dropout_rate=self.config.dropout_in_rate,\n",
    "                        num_units=self.config.num_units,\n",
    "                        num_heads=self.config.num_heads,\n",
    "                        is_causality=True,\n",
    "                        scope='self_attention'\n",
    "                    )\n",
    "                    decoder_inputs_embedded = transformer.multihead_attention(\n",
    "                        queries=decoder_inputs_embedded,\n",
    "                        keys=hier_encoder_inputs_embedded,\n",
    "                        is_training=self.is_training,\n",
    "                        dropout_rate=self.config.dropout_in_rate,\n",
    "                        num_units=self.config.num_units,\n",
    "                        num_heads=self.config.num_heads,\n",
    "                        is_causality=False,\n",
    "                        scope='vanilla_attention'\n",
    "                    )\n",
    "\n",
    "                    decoder_inputs_embedded = transformer.feedforward(\n",
    "                        decoder_inputs_embedded,\n",
    "                        num_units=[4*self.config.num_units, self.config.num_units]\n",
    "                    )\n",
    "\n",
    "            for i in range(self.config.num_layers):\n",
    "                with tf.variable_scope('shared_blocks'):\n",
    "                    decoder_inputs_embedded += transformer.positional_encoding2(\n",
    "                        decoder_inputs_embedded,\n",
    "                        is_zero_pad=True\n",
    "                    )\n",
    "                    decoder_inputs_embedded += transformer.step_encoding(\n",
    "                        decoder_inputs_embedded,\n",
    "                        i,\n",
    "                        is_zero_pad=True\n",
    "                    )\n",
    "                    decoder_inputs_embedded = transformer.multihead_attention(\n",
    "                        queries=decoder_inputs_embedded,\n",
    "                        keys=decoder_inputs_embedded,\n",
    "                        is_training=self.is_training,\n",
    "                        dropout_rate=self.config.dropout_in_rate,\n",
    "                        num_units=self.config.num_units,\n",
    "                        num_heads=self.config.num_heads,\n",
    "                        is_causality=True,\n",
    "                        scope='self_attention'\n",
    "                    )\n",
    "                    decoder_inputs_embedded = transformer.multihead_attention(\n",
    "                        queries=decoder_inputs_embedded,\n",
    "                        keys=hier_encoder_inputs_embedded,\n",
    "                        is_training=self.is_training,\n",
    "                        dropout_rate=self.config.dropout_in_rate,\n",
    "                        num_units=self.config.num_units,\n",
    "                        num_heads=self.config.num_heads,\n",
    "                        is_causality=False,\n",
    "                        scope='vanilla_attention'\n",
    "                    )\n",
    "\n",
    "                    decoder_inputs_embedded = transformer.feedforward(\n",
    "                        decoder_inputs_embedded,\n",
    "                        num_units=[4*self.config.num_units, self.config.num_units]\n",
    "                    )\n",
    "\n",
    "            for i in range(self.config.num_post_layers):\n",
    "                with tf.variable_scope('post_blocks_{}'.format(i)):\n",
    "                    decoder_inputs_embedded = transformer.multihead_attention(\n",
    "                        queries=decoder_inputs_embedded,\n",
    "                        keys=decoder_inputs_embedded,\n",
    "                        is_training=self.is_training,\n",
    "                        dropout_rate=self.config.dropout_in_rate,\n",
    "                        num_units=self.config.num_units,\n",
    "                        num_heads=self.config.num_heads,\n",
    "                        is_causality=True,\n",
    "                        scope='self_attention'\n",
    "                    )\n",
    "                    decoder_inputs_embedded = transformer.multihead_attention(\n",
    "                        queries=decoder_inputs_embedded,\n",
    "                        keys=hier_encoder_inputs_embedded,\n",
    "                        is_training=self.is_training,\n",
    "                        dropout_rate=self.config.dropout_in_rate,\n",
    "                        num_units=self.config.num_units,\n",
    "                        num_heads=self.config.num_heads,\n",
    "                        is_causality=False,\n",
    "                        scope='vanilla_attention'\n",
    "                    )\n",
    "\n",
    "                    decoder_inputs_embedded = transformer.feedforward(\n",
    "                        decoder_inputs_embedded,\n",
    "                        num_units=[4*self.config.num_units, self.config.num_units]\n",
    "                    )\n",
    "\n",
    "            decoder_logits = tf.layers.dense(decoder_inputs_embedded, self.config.vocab_size)\n",
    "\n",
    "            return decoder_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T09:02:54.474906Z",
     "start_time": "2018-09-24T09:02:54.367981Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T09:02:54.558417Z",
     "start_time": "2018-09-24T09:02:54.476266Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(configs, gpu_index, num_epochs=100):\n",
    "    for config in configs:\n",
    "        with tf.Graph().as_default():\n",
    "            with tf.device('/gpu:{}'.format(gpu_index)):\n",
    "                ds = DocomoDataSource(config)\n",
    "                model = Transformer(config, 'transformer')\n",
    "\n",
    "                global_step = tf.train.get_or_create_global_step()\n",
    "                optimizer = tf.train.AdamOptimizer(config.learning_rate)\n",
    "                train_op = optimizer.minimize(model.loss, global_step=global_step)\n",
    "\n",
    "\n",
    "                with tf.name_scope('summary'):\n",
    "                    loss_smr = tf.summary.scalar('loss', model.loss)\n",
    "                    acc_smr = tf.summary.scalar('acc', model.accuracy)\n",
    "                    merged_summary = tf.summary.merge_all()\n",
    "\n",
    "                tf_config = tf.ConfigProto(\n",
    "                    allow_soft_placement=True,\n",
    "                    gpu_options=tf.GPUOptions(\n",
    "                        allow_growth=True\n",
    "                    )\n",
    "                )\n",
    "                with tf.Session(config=tf_config) as sess:\n",
    "                    writer = tf.summary.FileWriter(model.config.to_log_dir() , sess.graph)\n",
    "                    sess.run(tf.global_variables_initializer())\n",
    "                    for epoch in range(num_epochs):\n",
    "                        ds.shuffle()\n",
    "                        batch_list = ds.feed_dict(model, model.config.batch_size, is_transformer=True)\n",
    "                        for fd in batch_list:\n",
    "                            fd[model.is_training] = True\n",
    "                            _, step, loss, acc, smr = sess.run([train_op, global_step, model.loss, model.accuracy, merged_summary], feed_dict=fd)\n",
    "                            #step = sess.run(global_step)\n",
    "                            writer.add_summary(smr, step)\n",
    "                            #if step % 100 == 0:\n",
    "                            #print('step: {}, loss: {:.3f}, acc: {:.3f}'.format(step, loss, acc))\n",
    "                        print('epoch {}/{} finished.'.format(epoch+1, num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T14:03:06.505559Z",
     "start_time": "2018-09-24T09:02:54.559753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/20 finished.\n",
      "epoch 2/20 finished.\n",
      "epoch 3/20 finished.\n",
      "epoch 4/20 finished.\n",
      "epoch 5/20 finished.\n",
      "epoch 6/20 finished.\n",
      "epoch 7/20 finished.\n",
      "epoch 8/20 finished.\n",
      "epoch 9/20 finished.\n",
      "epoch 10/20 finished.\n",
      "epoch 11/20 finished.\n",
      "epoch 12/20 finished.\n",
      "epoch 13/20 finished.\n",
      "epoch 14/20 finished.\n",
      "epoch 15/20 finished.\n",
      "epoch 16/20 finished.\n",
      "epoch 17/20 finished.\n",
      "epoch 18/20 finished.\n",
      "epoch 19/20 finished.\n",
      "epoch 20/20 finished.\n"
     ]
    }
   ],
   "source": [
    "run([config], 0, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T10:49:45.185311Z",
     "start_time": "2018-09-21T10:48:36.373Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
