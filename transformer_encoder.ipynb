{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T15:40:06.440941Z",
     "start_time": "2018-08-08T15:40:06.429887Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "from typing import List, Tuple, Dict, Callable, Optional, Any, Sequence, Mapping, NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T15:40:07.072998Z",
     "start_time": "2018-08-08T15:40:06.446509Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T15:40:07.078339Z",
     "start_time": "2018-08-08T15:40:07.074638Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.config import Config\n",
    "from data_loader.ptb_datasource import PTBDataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T15:40:07.135114Z",
     "start_time": "2018-08-08T15:40:07.079278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(num_units=512, num_layers=6, num_heads=8, num_outputs=10000, batch_size=128, max_length=50, dropout_in_rate=0.1, dropout_out_rate=0.2, learning_rate=0.001, grad_clip=5.0, is_layer_norm=False, data_path='./data/', log_dir='./logs/')\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T15:40:08.038904Z",
     "start_time": "2018-08-08T15:40:07.136419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "data = PTBDataSource(config)\n",
    "print(data.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T15:40:08.057590Z",
     "start_time": "2018-08-08T15:40:08.039986Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder:\n",
    "    \n",
    "    def __init__(self, config, vocab_size, reuse=None):\n",
    "        self._config = config\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        self._create_placeholder()\n",
    "        self._create_model(reuse)\n",
    "        \n",
    "    def _create_placeholder(self):\n",
    "        self.is_training = tf.placeholder(shape=(), dtype=tf.bool, name='is_training')\n",
    "        self.inputs_data = tf.placeholder(shape=[None, self._config.max_length], name='inputs_data', dtype=tf.int32)  # batch_size x max_length\n",
    "        self.targets_classes = tf.placeholder(shape=[None, self._config.num_outputs], name='targets_data', dtype=tf.int32)  # batch_size x num_outputs\n",
    "        \n",
    "    def _create_model(self, reuse):\n",
    "        with tf.variable_scope('transformer', reuse=reuse):\n",
    "            inputs = self.inputs_data\n",
    "            embedded_inputs = self._embedding(inputs, self._config.num_units)  # [batch_size, max_length, embedded_size]\n",
    "            embedded_inputs += self._positional_encoding(inputs)  # [batch_size, max_length, embedded_size]\n",
    "            encoded_queries = self._encode(embedded_inputs)\n",
    "            self.outputs_prob = self._dense(encoded_queries, self._config.num_outputs, 'outputs', tf.nn.softmax)\n",
    "            self.predicted_class = tf.argmax(self.outputs_prob, axis=-1)\n",
    "        \n",
    "    def _encode(self,\n",
    "                    inputs,  # [batch_size, max_length, num_units]\n",
    "                    scope: str='encoder'):\n",
    "        with tf.variable_scope(scope):\n",
    "            queries = inputs\n",
    "            encoded_queries = tf.get_variable('encoded_queries', \n",
    "                                                      dtype=tf.float32, \n",
    "                                                      shape=[1, self._config.num_units], \n",
    "                                                      initializer=tf.contrib.layers.xavier_initializer())\n",
    "            encoded_queries = tf.tile(tf.expand_dims(encoded_queries, 0), [tf.shape(inputs)[0], 1, 1])  # [batch_size, 1, num_units]\n",
    "            for i in range(self._config.num_layers):\n",
    "                with tf.variable_scope('block_{}'.format(i)):\n",
    "                    original_queries = queries\n",
    "                    queries = self._multihead_attention(\n",
    "                        keys=queries, \n",
    "                        queries=queries, \n",
    "                        num_units=self._config.num_units, \n",
    "                        num_heads=self._config.num_heads, \n",
    "                        causality=False,\n",
    "                        scope='self_attention',\n",
    "                        reuse=None\n",
    "                    )\n",
    "                    queries += original_queries\n",
    "                    queries = self._normalize(queries, scope='mh_normalize')\n",
    "                    \n",
    "                    original_queries = encoded_queries\n",
    "                    encoded_queries = self._multihead_attention(\n",
    "                        keys=queries,\n",
    "                        queries=encoded_queries,\n",
    "                        num_units=self._config.num_units,\n",
    "                        num_heads=self._config.num_heads,\n",
    "                        causality=False,\n",
    "                        reuse=None\n",
    "                    )\n",
    "                    encoded_queries += original_queries\n",
    "                    encoded_queries = self._normalize(encoded_queries)\n",
    "\n",
    "                    original_queries = queries\n",
    "                    queries = self._feedforward(queries, [self._config.num_units*4, self._config.num_units], dropout_rate=self._config.dropout_in_rate)\n",
    "                    queries += original_queries\n",
    "                    queries = self._normalize(queries, scope='ff_normalize')\n",
    "        return queries\n",
    "    \n",
    "    def _multihead_attention(self,\n",
    "                           keys,  # [batch_size, max_length, embedded_size]\n",
    "                           queries,\n",
    "                           num_units: int,\n",
    "                           num_heads: int=8,\n",
    "                           causality: bool=False,\n",
    "                           scope: str='multihead_attention',\n",
    "                           reuse: bool=None):\n",
    "        with tf.variable_scope(scope):\n",
    "            num_heads_units = num_units / num_heads\n",
    "            keys = self._dense(keys, num_units, 'keys')  # [batch_size, max_length, num_units]\n",
    "            values = self._dense(keys, num_units, 'values')\n",
    "            queries = self._dense(queries, num_units, 'queries')\n",
    "\n",
    "            mh_keys = tf.concat(tf.split(keys, num_heads, axis=2), axis=0)  # [batch_size*num_heads, max_length, num_units/num_heads]\n",
    "            mh_values = tf.concat(tf.split(values, num_heads, axis=2), axis=0)\n",
    "            mh_queries = tf.concat(tf.split(queries, num_heads, axis=2), axis=0)\n",
    "\n",
    "            key_masks = tf.sign(tf.abs(tf.reduce_sum(keys, axis=-1)))  # [batch_size, max_length]\n",
    "            key_masks = tf.tile(key_masks, [num_heads, 1])  # [batch_size*num_heads, max_length]\n",
    "            key_masks = tf.tile(tf.expand_dims(key_masks, 1), [1, tf.shape(queries)[1], 1])  # [batch_size*num_heads, max_length, max_length]\n",
    "\n",
    "            outputs = tf.matmul(mh_queries, tf.transpose(mh_keys, [0, 2, 1]))  # [batch_size*num_heads, max_length, max_length]\n",
    "            outputs = outputs / (num_heads_units)**0.5\n",
    "\n",
    "            paddings = tf.ones_like(outputs)*(-2**32+1)\n",
    "            outputs = tf.where(tf.equal(key_masks, 0), paddings, outputs)\n",
    "\n",
    "            outputs = tf.nn.softmax(outputs)\n",
    "            outputs = tf.matmul(outputs, mh_values)  # [batch_size*num_heads, max_length, num_units/num_heads]\n",
    "\n",
    "            outputs = tf.concat(tf.split(outputs, num_heads, axis=0), axis=2)  # [batch_size, max_length, num_units]\n",
    "\n",
    "            outputs = self._dense(outputs, num_units, 'output')\n",
    "        return outputs\n",
    "    \n",
    "    def _feedforward(self,\n",
    "                        inputs,\n",
    "                        num_units: List[int], # [num_layers, num_units]\n",
    "                        dropout_rate,\n",
    "                        scope: str='feedforward',\n",
    "                        reuse: bool=None):\n",
    "        with tf.variable_scope(scope):\n",
    "            layer = inputs\n",
    "            for (i, units) in enumerate(num_units):\n",
    "                layer = self._dense(layer, units, 'dense_{}'.format(i), tf.nn.relu)\n",
    "        return layer\n",
    "    \n",
    "    def _positional_encoding(self,\n",
    "                                inputs,\n",
    "                                is_zero_pad: bool=True,\n",
    "                                scope: str='positional_encoding'):\n",
    "        _, T = inputs.get_shape().as_list()\n",
    "        N, _ = tf.unstack(tf.shape(inputs))\n",
    "        \n",
    "        position_ind = tf.tile(tf.expand_dims(tf.range(T), 0), [N, 1])\n",
    "        \n",
    "        position_enc = np.array([\n",
    "            [pos / np.power(10000, 2.*i/self._config.num_units) for i in range(self._config.num_units)]\n",
    "            for pos in range(T)\n",
    "        ])\n",
    "        \n",
    "        position_enc[:, 0::2] = np.sin(position_enc[:, 0::2])\n",
    "        position_enc[:, 1::2] = np.cos(position_enc[:, 1::2])\n",
    "        \n",
    "        lookup_table = tf.convert_to_tensor(position_enc, dtype=tf.float32)\n",
    "        \n",
    "        outputs = tf.nn.embedding_lookup(lookup_table, position_ind)\n",
    "        \n",
    "        if is_zero_pad:\n",
    "            masks = tf.tile(tf.expand_dims(tf.sign(tf.abs(inputs)), -1), [1, 1, self._config.num_units])\n",
    "            paddings = tf.zeros_like(outputs)\n",
    "            outputs = tf.where(tf.equal(masks, 0), paddings, outputs)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def _embedding(self,\n",
    "                     inputs,\n",
    "                     num_units,\n",
    "                     is_zero_pad: bool=True,\n",
    "                     is_scale: bool=True,\n",
    "                     scope: str='embedding',\n",
    "                     reuse: bool=None):\n",
    "        with tf.variable_scope(scope, reuse=reuse):\n",
    "            lookup_table = tf.get_variable(\n",
    "                'lookup_table', \n",
    "                shape=[self.vocab_size, num_units],\n",
    "                dtype=tf.float32,\n",
    "                initializer=tf.contrib.layers.xavier_initializer()\n",
    "            )\n",
    "            if is_zero_pad:\n",
    "                lookup_table = tf.concat((tf.zeros(shape=[1, num_units]), lookup_table[1:, :]), 0)\n",
    "            embedded = tf.nn.embedding_lookup(lookup_table, inputs)\n",
    "            if is_scale:\n",
    "                embedded = embedded * num_units ** 0.5\n",
    "        return embedded\n",
    "    \n",
    "    def _normalize(self,\n",
    "                     inputs,\n",
    "                     epsilon=1e-8,\n",
    "                     scope='normalize',\n",
    "                     reuse: bool=None):\n",
    "        with tf.variable_scope(scope, reuse=reuse):\n",
    "            param_dim = inputs.get_shape()[-1]\n",
    "            mean, variance = tf.nn.moments(inputs, [-1], keep_dims=True)\n",
    "            \n",
    "            beta = tf.get_variable('beta', initializer=tf.zeros([param_dim]))\n",
    "            gamma = tf.get_variable('gamma', initializer=tf.ones([param_dim]))\n",
    "            normalized = (inputs - mean)/((variance+epsilon) **0.5)\n",
    "            normalized = normalized * gamma + beta\n",
    "        return normalized\n",
    "    \n",
    "    def _dense(self,\n",
    "                 inputs,\n",
    "                 num_units: int,\n",
    "                 scope: str,\n",
    "                 activation=None,\n",
    "                 dropout_rate: Optional[float]=None):\n",
    "        with tf.variable_scope(scope):\n",
    "            layer = tf.layers.dense(inputs, num_units, activation, name='dense')\n",
    "            if dropout_rate:\n",
    "                layer = tf.layers.dropout(layer, dropout_rate, training=self.is_training, name='dropout')\n",
    "        return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T15:40:10.170603Z",
     "start_time": "2018-08-08T15:40:08.058595Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_feedforward() got an unexpected keyword argument 'dropout_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5d1aff879573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-914cf69644dc>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, vocab_size, reuse)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_placeholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_create_placeholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-914cf69644dc>\u001b[0m in \u001b[0;36m_create_model\u001b[0;34m(self, reuse)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0membedded_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_units\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch_size, max_length, embedded_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0membedded_inputs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_positional_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch_size, max_length, embedded_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mencoded_queries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'outputs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-914cf69644dc>\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(self, inputs, scope)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0moriginal_queries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                     \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_units\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_units\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_in_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                     \u001b[0mqueries\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0moriginal_queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ff_normalize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _feedforward() got an unexpected keyword argument 'dropout_rate'"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    model = TransformerEncoder(config, data.vocab_size)\n",
    "    model.outputs_prob\n",
    "    model.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
